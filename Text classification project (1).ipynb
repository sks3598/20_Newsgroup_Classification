{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile,join\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = '20_newsgroups'\n",
    "\n",
    "#creating a list of folders name\n",
    "\n",
    "folders = [f for f in listdir(project_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a  list for storing all files in different folder\n",
    "\n",
    "files = []\n",
    "for folder_name in folders:\n",
    "    folder_path = join(project_path,folder_name)\n",
    "    files.append([f for f in listdir(folder_path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19997"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking total number of files gathered\n",
    "sum(len(files[i]) for i in range(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a list of pathnames of all documents\n",
    "all_paths = []\n",
    "for fol in range(len(folders)):\n",
    "    for fil in files[fol]:\n",
    "        all_paths.append(join(project_path,join(folders[fol],fil)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19997\n"
     ]
    }
   ],
   "source": [
    "print(len(all_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making an array of classes each documents belong to as this is going to help us splitting for taining and testing\n",
    "\n",
    "y=[]\n",
    "for folder_name in folders:\n",
    "    folder_path = join(project_path,folder_name)\n",
    "    no_of_file = len(listdir(folder_path))\n",
    "    for i in range(no_of_file):\n",
    "        y.append(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19997"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding all stopwords\n",
    "\n",
    "stopwords = ['a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and', 'any', 'are', \"aren't\", 'as', 'at',\n",
    " 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', \n",
    " 'can', \"can't\", 'cannot', 'could', \"couldn't\", 'did', \"didn't\", 'do', 'does', \"doesn't\", 'doing', \"don't\", 'down', 'during',\n",
    " 'each', 'few', 'for', 'from', 'further', \n",
    " 'had', \"hadn't\", 'has', \"hasn't\", 'have', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", \"he's\", 'her', 'here', \"here's\",\n",
    " 'hers', 'herself', 'him', 'himself', 'his', 'how', \"how's\",\n",
    " 'i', \"i'd\", \"i'll\", \"i'm\", \"i've\", 'if', 'in', 'into', 'is', \"isn't\", 'it', \"it's\", 'its', 'itself',\n",
    " \"let's\", 'me', 'more', 'most', \"mustn't\", 'my', 'myself',\n",
    " 'no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'ought', 'our', 'ours' 'ourselves', 'out', 'over', 'own',\n",
    " 'same', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', \"shouldn't\", 'so', 'some', 'such', \n",
    " 'than', 'that',\"that's\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', \"there's\", 'these', 'they', \"they'd\", \n",
    " \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 'very', \n",
    " 'was', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", \"we've\", 'were', \"weren't\", 'what', \"what's\", 'when', \"when's\", 'where',\n",
    " \"where's\", 'which', 'while', 'who', \"who's\", 'whom', 'why', \"why's\",'will', 'with', \"won't\", 'would', \"wouldn't\", \n",
    " 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves', \n",
    " 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'hundred', 'thousand', '1st', '2nd', '3rd',\n",
    " '4th', '5th', '6th', '7th', '8th', '9th', '10th']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary of words with their frquency\n",
    "vocab={}\n",
    "for i in all_paths:\n",
    "    # open the file and read it\n",
    "    text = open(i,'r',errors='ignore').read()\n",
    "    for word in text.split():\n",
    "        if len(word)!=1:\n",
    "            #check if the word is present in stop words or not\n",
    "            if not word.lower() in stopwords:\n",
    "                #if word is already in dictionary we will just increase its frequency by 1\n",
    "                if vocab.get(word.lower())!=None:\n",
    "                    vocab[word.lower()]+=1\n",
    "                # if word is not present in vocab then add the word in vocab with frequency = 1\n",
    "                else:\n",
    "                    vocab[word.lower()] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "425280"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the vocab on the basis of freq of words\n",
    "import operator\n",
    "sorted_vocab = sorted(vocab.items(),key=operator.itemgetter(1),reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('subject:', 20486),\n",
       " ('from:', 20417),\n",
       " ('date:', 20137),\n",
       " ('newsgroups:', 20081),\n",
       " ('message-id:', 20050),\n",
       " ('lines:', 20042),\n",
       " ('path:', 20029),\n",
       " ('apr', 19602),\n",
       " ('organization:', 19246),\n",
       " ('gmt', 17684),\n",
       " ('1993', 14414),\n",
       " ('re:', 14213),\n",
       " ('--', 14076),\n",
       " ('writes:', 14040),\n",
       " ('references:', 12548),\n",
       " ('article', 12108),\n",
       " ('|>', 11332),\n",
       " ('sender:', 10907),\n",
       " ('like', 9434),\n",
       " ('just', 9425)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_vocab[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = sorted_vocab[10000][1]\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary containing the most occuring k words\n",
    "kvocab = {}\n",
    "z = sorted_vocab[2000][1]\n",
    "for x in sorted_vocab:\n",
    "    kvocab[x[0]]=x[1]\n",
    "    if x[1]<z:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject:</th>\n",
       "      <th>from:</th>\n",
       "      <th>date:</th>\n",
       "      <th>newsgroups:</th>\n",
       "      <th>message-id:</th>\n",
       "      <th>lines:</th>\n",
       "      <th>path:</th>\n",
       "      <th>apr</th>\n",
       "      <th>organization:</th>\n",
       "      <th>gmt</th>\n",
       "      <th>...</th>\n",
       "      <th>forced</th>\n",
       "      <th>(2)</th>\n",
       "      <th>reduce</th>\n",
       "      <th>frame</th>\n",
       "      <th>2.5</th>\n",
       "      <th>200</th>\n",
       "      <th>june</th>\n",
       "      <th>tool</th>\n",
       "      <th>256</th>\n",
       "      <th>be.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2008 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject:  from:  date:  newsgroups:  message-id:  lines:  path:  apr  \\\n",
       "0       1.0    1.0    1.0          1.0          1.0     1.0    1.0  1.0   \n",
       "1       1.0    1.0    1.0          1.0          1.0     1.0    1.0  1.0   \n",
       "2       1.0    1.0    1.0          1.0          1.0     1.0    1.0  1.0   \n",
       "3       1.0    1.0    1.0          1.0          1.0     1.0    1.0  1.0   \n",
       "4       1.0    1.0    1.0          1.0          1.0     1.0    1.0  1.0   \n",
       "\n",
       "   organization:  gmt ...   forced  (2)  reduce  frame  2.5  200  june  tool  \\\n",
       "0            1.0  2.0 ...      0.0  0.0     0.0    0.0  0.0  0.0   0.0   0.0   \n",
       "1            1.0  2.0 ...      0.0  0.0     0.0    0.0  0.0  0.0   0.0   0.0   \n",
       "2            1.0  1.0 ...      0.0  0.0     0.0    0.0  0.0  0.0   0.0   0.0   \n",
       "3            1.0  1.0 ...      0.0  0.0     0.0    0.0  0.0  0.0   0.0   0.0   \n",
       "4            1.0  1.0 ...      0.0  0.0     0.0    0.0  0.0  0.0   0.0   0.0   \n",
       "\n",
       "   256  be.  \n",
       "0  0.0  0.0  \n",
       "1  0.0  1.0  \n",
       "2  0.0  0.0  \n",
       "3  0.0  0.0  \n",
       "4  0.0  0.0  \n",
       "\n",
       "[5 rows x 2008 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "features_list = list(kvocab.keys())\n",
    "\n",
    "## Create a Dataframe containing features_list as columns \n",
    "df = pd.DataFrame(columns = features_list)\n",
    "\n",
    "\n",
    "## Filling the x_train values in dataframe \n",
    "\n",
    "for i in range(len(folders)):\n",
    "    ##Create a list of files in the given dictionary \n",
    "    files = listdir('./20_newsgroups/' + folders[i])\n",
    " \n",
    "    for j in range(len(files)):\n",
    "        ##Insert a row at the end of Dataframe with all zeros\n",
    "        df.loc[len(df)] = np.zeros(len(features_list))\n",
    "        \n",
    "        ##Path of each file \n",
    "        path = './20_newsgroups/' + folders[i] + '/' + files[j]\n",
    "        \n",
    "        ##open the file and read it\n",
    "        text = open(path, 'r', errors='ignore').read()\n",
    "        \n",
    "        \n",
    "        for word in text.split():\n",
    "            if word.lower() in features_list:\n",
    "                df[word.lower()][len(df)-1] += 1\n",
    "                \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19997, 2008)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19997"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(features_list))\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.values\n",
    "\n",
    "f_list = list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19997"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(f_list))\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into training and testing groups\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14997, 2008)\n",
      "(5000, 2008)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "#print(y_train.shape)\n",
    "#print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_score  0.8254\n",
      "train_score 0.8685737147429486\n"
     ]
    }
   ],
   "source": [
    "#multinomial naive bias from sklearn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(x_train,y_train)\n",
    "y_predict = clf.predict(x_test)\n",
    "train_score = clf.score(x_train,y_train)\n",
    "test_score = clf.score(x_test,y_test)\n",
    "print(\"test_score \",test_score)\n",
    "print(\"train_score\",train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing our own multinomial naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x_train,y_train):\n",
    "    #dictionary count contains the frequency of each word\n",
    "    count = {}\n",
    "   \n",
    "    all_class = set(y_train)\n",
    "    for current_class in all_class:\n",
    "        count[current_class]={}\n",
    "        count[\"total_data\"] = len(y_train)\n",
    "        \n",
    "        # rows whose class is current class\n",
    "        \n",
    "        current_class_rows = (y_train==current_class)\n",
    "        x_train_current = x_train[current_class_rows]\n",
    "        y_train_current = y_train[current_class_rows]\n",
    "        count[current_class][\"total_count\"] = len(y_train_current)\n",
    "        sums = 0\n",
    "        \n",
    "        for i in range(len(f_list)):\n",
    "            ## For each class, calculating total frequency of a feature \n",
    "            count[current_class][f_list[i]] = x_train_current[:,i].sum()\n",
    "            sums = sums  + count[current_class][f_list[i]]\n",
    "            \n",
    "           ##Calculating total count of words of a class  \n",
    "        count[current_class][\"total_words\"] = sums\n",
    "        \n",
    "        \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(dictionary,row,current_class):\n",
    "    \n",
    "    #class probability\n",
    "    class_prob = np.log(dictionary[current_class][\"total_count\"]) - np.log(dictionary[\"total_data\"])\n",
    "    \n",
    "    for i in range(len(row)):\n",
    "        \n",
    "        #numerator\n",
    "        \n",
    "        count_i_word = dictionary[current_class][f_list[i]] + 1\n",
    "        \n",
    "        #denominator\n",
    "        total_words = dictionary[current_class][\"total_words\"] + len(f_list)\n",
    "        \n",
    "        #log prob of a particular word\n",
    "        word_prob = np.log(count_i_word) - np.log(total_words)\n",
    "        \n",
    "        ##Calculating probability frequency number of times\n",
    "        for j in range(int(row[i])):\n",
    "            class_prob = class_prob + word_prob\n",
    "    \n",
    "    return class_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_Single_point(dictionary,row):\n",
    "    \n",
    "    classes = dictionary.keys()\n",
    "    \n",
    "     ##Initialising best_prob and best_class with a low value\n",
    "    best_prob = -1000\n",
    "    best_class = -1\n",
    "    first_run = True\n",
    "    \n",
    "    for current_class in classes:\n",
    "        if current_class == \"total_data\":\n",
    "            continue\n",
    "        else:\n",
    "            \n",
    "             ##Calculating probabilty that the given row belong to current_class\n",
    "            prob_current_class = probability(dictionary,row,current_class)\n",
    "            \n",
    "            #for the first run we make the best prob as prob of first class and best class as first class\n",
    "            #for others we are checking the condition if its greater than the current best prob\n",
    "            if(first_run or prob_current_class > best_prob):\n",
    "                    best_prob = prob_current_class\n",
    "                    best_class = current_class\n",
    "                    \n",
    "                    \n",
    "        first_run = False\n",
    "        \n",
    "    # returns the best class for which the probability is maiximum\n",
    "    return best_class\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dictionary,x_test):\n",
    "    \n",
    "    #initialise a list which contains the predictions\n",
    "    y_pred1 = []\n",
    "    \n",
    "    #iterate through each row in x_test\n",
    "    for j in range(len(x_test)):\n",
    "        \n",
    "        #cal the prediction of the class to which row belongs to\n",
    "        pred_class = predict_Single_point(dictionary,x_test[j,:])\n",
    "        #append the result to the list\n",
    "        y_pred1.append(pred_class)\n",
    "        \n",
    "    return y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the model \n",
    "dictionary = fit(x_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tetsing the model\n",
    "y_pred_1 = predict(dictionary,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of sklearn MultinomialNB -  0.8254\n",
      "Accuracy of own implemented algo - 0.0462\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy of sklearn MultinomialNB - \" ,test_score)\n",
    "print(\"Accuracy of own implemented algo -\", accuracy_score(y_test,y_pred_1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report for sklearn MultinomialNB                           precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.69      0.83      0.75       245\n",
      "           comp.graphics       0.83      0.69      0.76       269\n",
      " comp.os.ms-windows.misc       0.90      0.77      0.83       282\n",
      "comp.sys.ibm.pc.hardware       0.80      0.85      0.82       230\n",
      "   comp.sys.mac.hardware       0.86      0.90      0.88       225\n",
      "          comp.windows.x       0.89      0.85      0.87       273\n",
      "            misc.forsale       0.69      0.91      0.78       223\n",
      "               rec.autos       0.81      0.91      0.86       253\n",
      "         rec.motorcycles       0.86      0.93      0.89       268\n",
      "      rec.sport.baseball       0.94      0.97      0.95       250\n",
      "        rec.sport.hockey       0.98      0.96      0.97       265\n",
      "               sci.crypt       0.97      0.87      0.92       262\n",
      "         sci.electronics       0.75      0.88      0.81       237\n",
      "                 sci.med       0.87      0.87      0.87       264\n",
      "               sci.space       0.88      0.83      0.85       248\n",
      "  soc.religion.christian       0.96      0.97      0.97       234\n",
      "      talk.politics.guns       0.72      0.87      0.78       238\n",
      "   talk.politics.mideast       0.89      0.84      0.87       245\n",
      "      talk.politics.misc       0.71      0.57      0.63       257\n",
      "      talk.religion.misc       0.61      0.38      0.47       232\n",
      "\n",
      "             avg / total       0.83      0.83      0.83      5000\n",
      "\n",
      "\n",
      "classification report for own implementd algo                            precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.00      0.00      0.00       245\n",
      "           comp.graphics       0.00      0.00      0.00       269\n",
      " comp.os.ms-windows.misc       0.00      0.00      0.00       282\n",
      "comp.sys.ibm.pc.hardware       0.00      0.00      0.00       230\n",
      "   comp.sys.mac.hardware       0.00      0.00      0.00       225\n",
      "          comp.windows.x       0.00      0.00      0.00       273\n",
      "            misc.forsale       0.00      0.00      0.00       223\n",
      "               rec.autos       0.00      0.00      0.00       253\n",
      "         rec.motorcycles       0.00      0.00      0.00       268\n",
      "      rec.sport.baseball       0.00      0.00      0.00       250\n",
      "        rec.sport.hockey       0.05      1.00      0.10       265\n",
      "               sci.crypt       0.00      0.00      0.00       262\n",
      "         sci.electronics       0.00      0.00      0.00       237\n",
      "                 sci.med       0.00      0.00      0.00       264\n",
      "               sci.space       0.00      0.00      0.00       248\n",
      "  soc.religion.christian       0.00      0.00      0.00       234\n",
      "      talk.politics.guns       0.00      0.00      0.00       238\n",
      "   talk.politics.mideast       0.00      0.00      0.00       245\n",
      "      talk.politics.misc       0.00      0.00      0.00       257\n",
      "      talk.religion.misc       0.00      0.00      0.00       232\n",
      "\n",
      "             avg / total       0.00      0.05      0.01      5000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"classification report for sklearn MultinomialNB\",classification_report(y_test,y_predict))\n",
    "print()\n",
    "print(\"classification report for own implementd algo \",classification_report(y_test,y_pred_1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
